{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31a0bf2a-35d4-4d01-a0c2-5ae0c714ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import chardet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb43a9d2-4fc5-4191-9230-a7a5369b5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n",
      "Index(['id', 'name', 'genres', 'type', 'episodes', 'status', 'aired_from',\n",
      "       'aired_to', 'duration_per_ep', 'score', 'scored_by', 'rank', 'rating',\n",
      "       'studios', 'producers', 'image', 'trailer', 'synopsis'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"popular_anime.csv\", \"rb\") as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "df=pd.read_csv(\"popular_anime.csv\",encoding=\"utf-8\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1357e29-8996-45ac-88b3-c0584fc23587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trailer            81.009540\n",
      "aired_to           62.081526\n",
      "producers          53.332177\n",
      "studios            41.245447\n",
      "score              35.476149\n",
      "scored_by          35.476149\n",
      "rank               23.809193\n",
      "genres             21.054640\n",
      "synopsis           18.622723\n",
      "aired_from          3.313096\n",
      "episodes            2.702515\n",
      "rating              2.511709\n",
      "type                0.301821\n",
      "name                0.000000\n",
      "duration_per_ep     0.000000\n",
      "status              0.000000\n",
      "image               0.000000\n",
      "id                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "emptydatapercentage=df.isnull().mean()*100\n",
    "print(emptydatapercentage.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d05e240d-07e5-4d2a-8685-1e4037f3508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aired_to', 'trailer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop=emptydatapercentage[emptydatapercentage>60].index\n",
    "print(cols_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55838012-b932-490f-96d1-66653acd7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.base.Index'>\n",
      "Index(['aired_to', 'trailer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(type(cols_to_drop))\n",
    "print(cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd033520-d5af-4f8d-b9ac-ba3e5693ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'genres', 'type', 'episodes', 'status', 'aired_from', 'aired_to', 'duration_per_ep', 'score', 'scored_by', 'rank', 'rating', 'studios', 'producers', 'image', 'trailer', 'synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13aa3242-9317-402f-8f43-8e9a4ec4006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   int64\n",
      "name                object\n",
      "genres              object\n",
      "type                object\n",
      "episodes           float64\n",
      "status              object\n",
      "aired_from          object\n",
      "aired_to            object\n",
      "duration_per_ep     object\n",
      "score              float64\n",
      "scored_by          float64\n",
      "rank               float64\n",
      "rating              object\n",
      "studios             object\n",
      "producers           object\n",
      "image               object\n",
      "trailer             object\n",
      "synopsis            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f99a24a-e221-47f2-9aab-14e85afa341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aired_from'] = pd.to_datetime(df['aired_from'], errors='coerce')\n",
    "\n",
    "\n",
    "# duration_per_ep'deki s√ºreyi dakikaya √ßevir\n",
    "df['duration_per_ep_minutes'] = df['duration_per_ep'].str.extract('(\\\\d+)').astype(float)\n",
    "\n",
    "# Kategorik s√ºtunlarƒ± d√∂n√º≈üt√ºr\n",
    "df['status'] = df['status'].astype('category')\n",
    "df['type'] = df['type'].astype('category')\n",
    "df['rating'] = df['rating'].astype('category')\n",
    "df['genres'] = df['genres'].astype('category')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca653ed4-e2b7-47bd-ab08-8fe37fe77c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                       int64\n",
      "name                                    object\n",
      "genres                                category\n",
      "type                                  category\n",
      "episodes                               float64\n",
      "status                                category\n",
      "aired_from                 datetime64[ns, UTC]\n",
      "aired_to                                object\n",
      "duration_per_ep                         object\n",
      "score                                  float64\n",
      "scored_by                              float64\n",
      "rank                                   float64\n",
      "rating                                category\n",
      "studios                                 object\n",
      "producers                               object\n",
      "image                                   object\n",
      "trailer                                 object\n",
      "synopsis                                object\n",
      "duration_per_ep_minutes                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31be3497-f034-4dac-9570-1ef94f1fe171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trailer            81.009540\n",
      "aired_to           62.081526\n",
      "producers          53.332177\n",
      "studios            41.245447\n",
      "score              35.476149\n",
      "scored_by          35.476149\n",
      "rank               23.809193\n",
      "genres             21.054640\n",
      "synopsis           18.622723\n",
      "aired_from          3.313096\n",
      "episodes            2.702515\n",
      "rating              2.511709\n",
      "type                0.301821\n",
      "name                0.000000\n",
      "duration_per_ep     0.000000\n",
      "status              0.000000\n",
      "image               0.000000\n",
      "id                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(emptydatapercentage.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91260150-5b4e-42ac-be18-6a3f5a66f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['studios','producers','aired_to','image','trailer'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26576df4-bc58-4e7b-9384-2bd096646b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['genres', 'type', 'status', 'rating']:\n",
    "    if col in df.columns and df[col].dtype.name == 'category':\n",
    "        if 'Unknown' not in df[col].cat.categories:\n",
    "            df[col] = df[col].cat.add_categories(['Unknown'])\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "for col in ['episodes', 'duration_per_ep_minutes','score','scored_by','rank','rating']:\n",
    "    if col in df.columns and df[col].dtype.name == 'category':\n",
    "        if '-1,0,23' not in df[col].cat.categories:\n",
    "            df[col] = df[col].cat.add_categories([-1,0,23])\n",
    "    \n",
    "\n",
    "df.fillna({\n",
    "    'name': 'Unknown',\n",
    "    'genres': 'Unknown',\n",
    "    'type': df['type'].mode()[0],\n",
    "    'episodes': 23,\n",
    "    'status': df['status'].mode()[0],\n",
    "    'aired_from': pd.Timestamp('2000-01-01'),\n",
    "    'aired_to': pd.Timestamp('2000-01-01'),\n",
    "    'duration_per_ep_minutes': 24,\n",
    "    'score': 0,\n",
    "    'scored_by': df['scored_by'].median(),\n",
    "    'rank': -1,\n",
    "    'rating': 0,\n",
    "    'image': 'No image',\n",
    "    'trailer': 'No trailer',\n",
    "    'synopsis': 'No synopsis available'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc0b48ef-e900-437f-ad93-ed8efb4fda5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28825 entries, 0 to 28824\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   id                       28825 non-null  int64   \n",
      " 1   name                     28825 non-null  object  \n",
      " 2   genres                   28825 non-null  category\n",
      " 3   type                     28825 non-null  category\n",
      " 4   episodes                 28825 non-null  float64 \n",
      " 5   status                   28825 non-null  category\n",
      " 6   aired_from               28825 non-null  object  \n",
      " 7   duration_per_ep          28825 non-null  object  \n",
      " 8   score                    28825 non-null  float64 \n",
      " 9   scored_by                28825 non-null  float64 \n",
      " 10  rank                     28825 non-null  float64 \n",
      " 11  rating                   28825 non-null  category\n",
      " 12  synopsis                 28825 non-null  object  \n",
      " 13  duration_per_ep_minutes  28825 non-null  float64 \n",
      "dtypes: category(4), float64(5), int64(1), object(4)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffe6d073-bd44-448e-b422-09abbfdc4b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "TV            8249\n",
      "Movie         4836\n",
      "OVA           4166\n",
      "Music         4087\n",
      "ONA           4076\n",
      "Special       1779\n",
      "TV Special     745\n",
      "CM             504\n",
      "PV             296\n",
      "Unknown         87\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a272084-e4ef-4a27-8f60-58ac93bcf64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- name ---\n",
      "name\n",
      "Spirit Guardians                               5\n",
      "Promise                                        5\n",
      "Happy Heroes: Rebel Rescue                     4\n",
      "Cyborg 009                                     4\n",
      "Meow Meow Japanese History                     4\n",
      "                                              ..\n",
      "Pyuu to Fuku! Jaguar: Ima, Fuki ni Yukimasu    1\n",
      "Argento Soma: Hitori to Hitori                 1\n",
      "Yurumates                                      1\n",
      "The Fleet of the Rising Sun                    1\n",
      "Marin X                                        1\n",
      "Name: count, Length: 28350, dtype: int64\n",
      "\n",
      "\n",
      "--- genres ---\n",
      "genres\n",
      "Unknown                                            6069\n",
      "Comedy                                             2621\n",
      "Fantasy                                            1462\n",
      "Hentai                                             1293\n",
      "Slice of Life                                       821\n",
      "                                                   ... \n",
      "Boys Love, Drama, Horror, Mystery, Supernatural       1\n",
      "Boys Love, Drama, Horror, Hentai                      1\n",
      "Boys Love, Drama, Hentai                              1\n",
      "Boys Love, Drama, Fantasy, Sci-Fi, Supernatural       1\n",
      "Adventure, Mystery, Sci-Fi, Slice of Life             1\n",
      "Name: count, Length: 936, dtype: int64\n",
      "\n",
      "\n",
      "--- type ---\n",
      "type\n",
      "TV            8249\n",
      "Movie         4836\n",
      "OVA           4166\n",
      "Music         4087\n",
      "ONA           4076\n",
      "Special       1779\n",
      "TV Special     745\n",
      "CM             504\n",
      "PV             296\n",
      "Unknown         87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- status ---\n",
      "status\n",
      "Finished Airing     27813\n",
      "Not yet aired         632\n",
      "Currently Airing      380\n",
      "Unknown                 0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- aired_from ---\n",
      "aired_from\n",
      "2000-01-01 00:00:00          955\n",
      "2012-01-01 00:00:00+00:00    159\n",
      "2011-01-01 00:00:00+00:00    156\n",
      "2010-01-01 00:00:00+00:00    143\n",
      "2019-01-01 00:00:00+00:00    140\n",
      "                            ... \n",
      "2012-02-23 00:00:00+00:00      1\n",
      "2002-09-09 00:00:00+00:00      1\n",
      "2009-06-30 00:00:00+00:00      1\n",
      "1981-09-07 00:00:00+00:00      1\n",
      "1978-07-31 00:00:00+00:00      1\n",
      "Name: count, Length: 9252, dtype: int64\n",
      "\n",
      "\n",
      "--- duration_per_ep ---\n",
      "duration_per_ep\n",
      "24 min per ep         2078\n",
      "23 min per ep         1819\n",
      "2 min                 1687\n",
      "3 min                 1629\n",
      "4 min                 1198\n",
      "                      ... \n",
      "24 sec                   1\n",
      "2 hr 35 min              1\n",
      "1 hr 7 min per ep        1\n",
      "1 hr 16 min per ep       1\n",
      "43 sec per ep            1\n",
      "Name: count, Length: 345, dtype: int64\n",
      "\n",
      "\n",
      "--- rating ---\n",
      "rating\n",
      "PG-13 - Teens 13 or older         10413\n",
      "G - All Ages                       8963\n",
      "PG - Children                      4354\n",
      "R - 17+ (violence & profanity)     1586\n",
      "Rx - Hentai                        1575\n",
      "R+ - Mild Nudity                   1210\n",
      "Unknown                             724\n",
      "-1                                    0\n",
      "0                                     0\n",
      "23                                    0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- synopsis ---\n",
      "synopsis\n",
      "No synopsis available                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           5368\n",
      "Music video for the so                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            64\n",
      "Music video for the song                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          51\n",
      "Music video for the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               46\n",
      "Music video for t                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 46\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ... \n",
      "In a world where only Pok√©mon live, one Hikozaru wishes to be part of Pukurin Guild‚Äîa large area where Exploration Teams gather and work. Intimidated by the apparent strength of the guild members and the guild's security, Hikozaru runs away, stumbling over an unconscious Pochama in the middle of his escape. The Pochama wakes up and is immediately shocked by both a talking Hikozaru as well as his own appearance‚Äîbecause Pochama knows that he is actually a human!\\n\\nWith Pochama having no memories aside from previously being human (as well as countless questions about his new body), Hikozaru suggests that he ask the leader of Pukurin Guild for help. While Guildmaster Pukurin may not have answers about Pochama's transformation, he decides to make Pochama and Hikozaru an Exploration Team, which HIkozaru calls Pok√©dans. For their first mission, the duo must get a Gabite Scale by going to Labyrinth Cave with Kimawari!       1\n",
      "After destroying the Zorbados Empire, the Jyusenki-tai/Cyber Beast Force has expanded and are training new recruits. But after failing to stop a monster that seems to be a remnant of the Zorbados Empire from destroying a city, the CBF is thrown in jail. Now the CBF have to escape from jail and find out what was behind the monster t                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "Di Gi Charat (call her Dejiko for short) and Petit Charat (the cute little charat) come down to Earth, where they want to be idols, or something like that. Rabi~en~Rose (a random girl with bunny ears) decides they're in her way of becoming an idol herself. They all end up working at Gamers, where various otaku, children, and humanoid fingers walk in and act like morons.\\n\\nContains:\\nGema no Sumika\\nTsusode shiu Engekidan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      "Unaired series episode in                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      "A Korean animated movie mixing Mecha w                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      "Name: count, Length: 21992, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.select_dtypes(include=['object', 'category']):\n",
    "    print(f\"--- {col} ---\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ae11020-207f-4f20-bd91-271537b72113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11c6fd3a-730f-4693-b03e-219e26b5d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_anime_name(name):\n",
    "    name = re.sub(r\"Season\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Final\\s*Season.*\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Part\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"\\s*:\\s*.*$\", \"\", name, flags=re.IGNORECASE)  # isimden sonrasƒ±nƒ± sil\n",
    "    name = name.strip()\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d58b1cae-0993-4289-aa21-95fd46c39fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset y√ºkle\n",
    "df = pd.read_csv('popular_anime.csv')\n",
    "\n",
    "# synopsis s√ºtununu doldur\n",
    "df['synopsis'] = df['synopsis'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "476636fe-b52f-4862-8459-09884a97b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_clean'] = df['name'].apply(clean_anime_name)\n",
    "df['name_lower'] = df['name'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c19e37f-7922-4887-8dbd-26190bd77d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_type_group(x):\n",
    "    if x in ['TV', 'OVA', 'ONA', 'Special']:\n",
    "        return 'TV_GROUP'\n",
    "    elif x == 'Movie':\n",
    "        return 'MOVIE_GROUP'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "df['type_group'] = df['type'].apply(map_type_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf295884-4d64-4ec0-af68-aab7e4b7382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN isimleri sil\n",
    "df_clean = df.dropna(subset=['name_clean'])\n",
    "\n",
    "# en y√ºksek skoru al\n",
    "df_dedup = (\n",
    "    df_clean\n",
    "    .sort_values('score', ascending=False)\n",
    "    .drop_duplicates(subset=['name_clean', 'type_group'], keep='first')\n",
    ")\n",
    "\n",
    "# TV ve Movie DataFrame'leri olu≈ütur\n",
    "tv_final_df = df_dedup[df_dedup['type_group'] == 'TV_GROUP']\n",
    "movie_final_df = df_dedup[df_dedup['type_group'] == 'MOVIE_GROUP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f373536-5a61-4175-a768-c16e7a10d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TV synopsis listesi\n",
    "tv_synopsis_list = tv_final_df['synopsis'].tolist()\n",
    "# 1. Veri temizliƒüi (zaten yapmƒ±≈üsƒ±n ama synopsis uzunluk filtresi ekleniyor)\n",
    "\n",
    "df_filtered = df[df['synopsis'].str.len() >= 30].copy()\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df_filtered['synopsis'])\n",
    "\n",
    "# TF-IDF vekt√∂rizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Movie synopsis listesi\n",
    "movie_synopsis_list = movie_final_df['synopsis'].tolist()\n",
    "\n",
    "vectorizer_movie = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix_movie = vectorizer_movie.fit_transform(movie_synopsis_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "144f2f34-2f6f-4aa2-8256-76fd320451e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\ertugrultetik\\anaconda3\\lib\\site-packages (3.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6d380eef-7949-45a8-b7f3-df1b2e852e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6d0c755-4883-43dd-965a-d02f0659aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_anime_name(name):\n",
    "    if pd.isnull(name): return \"\"\n",
    "    name = re.sub(r\"Season\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Final\\s*Season.*\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Part\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", name)\n",
    "    return name.strip().lower()\n",
    "\n",
    "def normalize(text): return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd76da75-b28b-4b92-8231-43011b0a86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TV ve Movie veri setlerine g√ºvenli bir ≈üekilde 'source' ekle\n",
    "tv_final_df = tv_final_df.copy()\n",
    "tv_final_df[\"source\"] = \"tv\"\n",
    "\n",
    "movie_final_df = movie_final_df.copy()\n",
    "movie_final_df[\"source\"] = \"movie\"\n",
    "remove_types = [\"Special\", \"OVA\", \"ONA\", \"Music\", \"Recap\"]\n",
    "\n",
    "def clean_df(df):\n",
    "    return df[\n",
    "        df[\"synopsis\"].notnull() &\n",
    "        df[\"name\"].notnull() &\n",
    "        (df[\"score\"].fillna(0) >= 5.0) &\n",
    "        (~df[\"type\"].isin(remove_types)) &\n",
    "        (df[\"episodes\"].fillna(2) > 1)\n",
    "    ]\n",
    "\n",
    "tv_final_df = clean_df(tv_final_df)\n",
    "movie_final_df = clean_df(movie_final_df)\n",
    "\n",
    "# Birle≈ütir ve yeni df_all'u garanti bir kopya olarak al\n",
    "df_all = pd.concat([tv_final_df, movie_final_df], ignore_index=True).copy()\n",
    "\n",
    "# G√ºvenli ≈üekilde temizleme i≈ülemleri\n",
    "df_all[\"base_name\"] = df_all[\"name\"].apply(clean_anime_name).str.lower()\n",
    "\n",
    "df_all[\"combined_text\"] = (\n",
    "    df_all[\"synopsis\"].fillna(\"\") + \" \" +\n",
    "    df_all[\"genres\"].fillna(\"\") + \" \" +\n",
    "    df_all[\"type\"].fillna(\"\") + \" \" +\n",
    "    df_all[\"rating\"].fillna(\"\")\n",
    ").str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "14033af8-f6e0-4fb2-8970-7b0c8a01bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def fuzzy_merge(df_base, df_additional, on='base_name', threshold=90):\n",
    "    matches = []\n",
    "    for name in df_base[on]:\n",
    "        match = process.extractOne(name, df_additional['English name cleaned'], scorer=fuzz.token_sort_ratio)\n",
    "        if match and match[1] >= threshold:\n",
    "            row = df_additional[df_additional['English name cleaned'] == match[0]]\n",
    "            if not row.empty:\n",
    "                row_data = {\n",
    "                    \"Score\": row[\"Score\"].values[0] if \"Score\" in row else np.nan,\n",
    "                    \"Rank\": row[\"Rank\"].values[0] if \"Rank\" in row else np.nan,\n",
    "                    \"Popularity\": row[\"Popularity\"].values[0] if \"Popularity\" in row else np.nan\n",
    "                }\n",
    "                matches.append(pd.Series(row_data))\n",
    "            else:\n",
    "                matches.append(pd.Series({\"Score\": np.nan, \"Rank\": np.nan, \"Popularity\": np.nan}))\n",
    "        else:\n",
    "            matches.append(pd.Series({\"Score\": np.nan, \"Rank\": np.nan, \"Popularity\": np.nan}))\n",
    "    scores_df = pd.DataFrame(matches).reset_index(drop=True)\n",
    "    return pd.concat([df_base.reset_index(drop=True), scores_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9410ef52-0454-44e5-aa14-70fd14b0e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix_all = vectorizer.fit_transform(df_all[\"combined_text\"])\n",
    "# anime-dataset-2023.csv dosyasƒ±nƒ± oku\n",
    "df2 = pd.read_csv(\"anime-dataset-2023.csv\")\n",
    "df2[\"English name cleaned\"] = df2[\"English name\"].fillna(df2[\"Name\"]).apply(clean_anime_name)\n",
    "# Gereksiz kolonlarƒ± sil\n",
    "drop_cols = [\n",
    "    \"Producers\", \"Licensors\", \"Premiered\",\n",
    "    \"Broadcast\", \"Opening Theme\", \"Ending Theme\", \"Background\"\n",
    "]\n",
    "df_all.drop(columns=[col for col in drop_cols if col in df_all.columns], inplace=True)\n",
    "# Merge et\n",
    "df_all = fuzzy_merge(df_all, df2)\n",
    "df_all[\"Score\"] = pd.to_numeric(df_all[\"Score\"], errors=\"coerce\")\n",
    "\n",
    "# Satƒ±r bazlƒ± temizlik\n",
    "df_all = df_all[df_all[\"synopsis\"].notnull() & df_all[\"name\"].notnull()]\n",
    "df_all = df_all[df_all[\"Score\"].fillna(0) > 4]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5f1e8aa4-fad3-4a1e-8130-ef99bc693eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Gerekli kolonlar\n",
    "required_cols = [\"Score\", \"Rank\", \"Popularity\"]\n",
    "\n",
    "# Eksik olan kolonlarƒ± ekle ve tipleri d√∂n√º≈üt√ºr\n",
    "for col in required_cols:\n",
    "    if col not in df_all.columns:\n",
    "        df_all[col] = np.nan\n",
    "\n",
    "# Tip kontrol√º: Sayƒ±sal deƒüilse d√∂n√º≈üt√ºr\n",
    "for col in required_cols:\n",
    "    df_all[col] = pd.to_numeric(df_all[col], errors='coerce')\n",
    "\n",
    "# Ortalamayla doldur\n",
    "df_all[required_cols] = df_all[required_cols].fillna(df_all[required_cols].mean())\n",
    "\n",
    "# Normalize et\n",
    "scaler = MinMaxScaler()\n",
    "df_all[[\"norm_score\", \"norm_rank\", \"norm_popularity\"]] = scaler.fit_transform(df_all[required_cols])\n",
    "\n",
    "# Quality Score hesapla (score y√ºksek, rank/popularity d√º≈ü√ºk iyidir)\n",
    "df_all[\"quality_score\"] = (\n",
    "    df_all[\"norm_score\"] * 0.5 +\n",
    "    (1 - df_all[\"norm_rank\"]) * 0.3 +\n",
    "    (1 - df_all[\"norm_popularity\"]) * 0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c94a1d9c-9896-43b3-89ba-62431eee50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d2901452-dfaf-48ca-947e-f9586bcb4111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• L√ºtfen en az 1, en fazla 5 anime ismi giriniz.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1. anime ismi (bitirmek i√ßin bo≈ü bƒ±rak ve Enter'a bas):  91 days\n",
      "2. anime ismi (bitirmek i√ßin bo≈ü bƒ±rak ve Enter'a bas):   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ '91 days' e≈üle≈üti ‚Üí '91 days'\n",
      "\n",
      "üéØ Final Skor ile En ƒ∞yi 10 Anime √ñnerisi:\n",
      "                                    name  score                                             genres  quality_score\n",
      "0  JoJo's Bizarre Adventure: Golden Wind   8.58                                  Action, Adventure       0.932779\n",
      "1                                 Erased   8.30                                  Mystery, Suspense       0.897636\n",
      "2        The Eminence in Shadow Season 2   8.29                            Action, Comedy, Fantasy       0.895557\n",
      "3                      The Tatami Galaxy   8.55  Award Winning, Comedy, Mystery, Romance, Suspense       0.927375\n",
      "4        Fruits Basket: The Final Season   8.95                       Drama, Romance, Supernatural       0.981753\n",
      "5                            Banana Fish   8.45                 Action, Adventure, Drama, Suspense       0.918834\n",
      "6                 The Promised Neverland   8.48                                  Mystery, Suspense       0.924767\n",
      "7                       Samurai Champloo   8.52                          Action, Adventure, Comedy       0.924003\n",
      "8                       To Your Eternity   8.34                     Adventure, Drama, Supernatural       0.902617\n",
      "9        Bleach: Thousand-Year Blood War   8.99                    Action, Adventure, Supernatural       0.990863\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ Kullanƒ±lacak veriyi filtrele (√∂rneƒüin synopsis kƒ±sa olanlarƒ± at)\n",
    "df_filtered = df_all[df_all[\"synopsis\"].str.len() >= 30].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)  # index karƒ±≈üƒ±klƒ±ƒüƒ±nƒ± √∂nlemek i√ßin sƒ±fƒ±rla\n",
    "\n",
    "# 2Ô∏è‚É£ TF-IDF matrisini olu≈ütur\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix_filtered = vectorizer.fit_transform(df_filtered[\"combined_text\"])\n",
    "\n",
    "# 3Ô∏è‚É£ Kullanƒ±cƒ±dan anime isimleri al\n",
    "print(\"üì• L√ºtfen en az 1, en fazla 5 anime ismi giriniz.\")\n",
    "user_inputs = []\n",
    "while len(user_inputs) < 5:\n",
    "    anime_name = input(f\"{len(user_inputs)+1}. anime ismi (bitirmek i√ßin bo≈ü bƒ±rak ve Enter'a bas): \").strip()\n",
    "    if anime_name == '':\n",
    "        break\n",
    "    user_inputs.append(anime_name)\n",
    "\n",
    "if not user_inputs:\n",
    "    print(\"‚ùå En az bir anime ismi girmelisiniz.\")\n",
    "    exit()\n",
    "\n",
    "# 4Ô∏è‚É£ Anime isimlerini fuzzy match ile e≈üle≈ütir\n",
    "matched_indices = []\n",
    "for anime in user_inputs:\n",
    "    cleaned_input = normalize(anime)\n",
    "    best_match = process.extractOne(cleaned_input, df_filtered[\"base_name\"].tolist(), score_cutoff=80)\n",
    "    if best_match:\n",
    "        idx = df_filtered[df_filtered[\"base_name\"] == best_match[0]].index\n",
    "        if not idx.empty:\n",
    "            matched_indices.append(idx[0])\n",
    "        print(f\"‚úÖ '{anime}' e≈üle≈üti ‚Üí '{best_match[0]}'\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è '{anime}' i√ßin e≈üle≈üme bulunamadƒ±.\")\n",
    "\n",
    "if not matched_indices:\n",
    "    print(\"‚ùå Hi√ßbir ge√ßerli e≈üle≈üme bulunamadƒ±.\")\n",
    "    exit()\n",
    "\n",
    "# 5Ô∏è‚É£ TF-IDF ortalama vekt√∂r√ºn√º hesapla\n",
    "input_vecs = tfidf_matrix_filtered[matched_indices]\n",
    "mean_vec = input_vecs.mean(axis=0)\n",
    "mean_vec = np.array(mean_vec)\n",
    "\n",
    "# 6Ô∏è‚É£ Cosine similarity ile benzerlikleri bul\n",
    "cosine_sim = cosine_similarity(mean_vec, tfidf_matrix_filtered).flatten()\n",
    "\n",
    "# 7Ô∏è‚É£ Final skoru hesapla (benzerlik ve kalite skoru birlikte)\n",
    "scored = []\n",
    "for i, sim in enumerate(cosine_sim):\n",
    "    qual = df_filtered.iloc[i]['quality_score'] if not pd.isna(df_filtered.iloc[i]['quality_score']) else 0\n",
    "    final_score = 0.8 * sim + 0.2 * qual\n",
    "    scored.append((i, final_score))\n",
    "\n",
    "\n",
    "# 8Ô∏è‚É£ En iyi 10 sonucu al (kullanƒ±cƒ±nƒ±n girdiklerini √ßƒ±kar)\n",
    "top10 = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "top10 = [item for item in top10 if item[0] not in matched_indices][:10]\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# 9Ô∏è‚É£ √ñnerileri yazdƒ±r\n",
    "print(\"\\nüéØ Final Skor ile En ƒ∞yi 10 Anime √ñnerisi:\")\n",
    "recommendations = df_filtered.iloc[[i for i, _ in top10]][['name', 'score', 'genres', 'quality_score']]\n",
    "recommendations.reset_index(drop=True, inplace=True)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da01e9e1-00e5-4692-9042-cb77879955c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score   Rank  Popularity\n",
      "1   9.10    1.0         3.0\n",
      "2   9.07    3.0        13.0\n",
      "3   8.94   16.0       138.0\n",
      "4   8.54  107.0         1.0\n",
      "5   8.41  170.0       357.0\n"
     ]
    }
   ],
   "source": [
    "print(df_all[['Score', 'Rank', 'Popularity']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e450db34-4b31-4c62-ac67-d16be8430ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8233, 21)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['synopsis'].str.len() < 30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "67b43e76-925f-4a74-ab41-4bc710d77ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (4392, 29401)\n",
      "df_all shape: (2723, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF shape:\", tfidf_matrix_all.shape)\n",
    "print(\"df_all shape:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7d8b8310-e509-4e36-96fb-55fabc8e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"anime_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f2951ac-65fc-4222-b3ce-8257e5bd78c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 14:54:08.995 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your preprocessed anime dataset here\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"anime_cleaned.csv\")  # senin temizlenmi≈ü df_filtered.csv\n",
    "    df = df[df[\"synopsis\"].str.len() >= 30].copy()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "@st.cache_resource\n",
    "def vectorize_text(df):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['combined_text'])\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "vectorizer, tfidf_matrix = vectorize_text(df)\n",
    "\n",
    "# Normalizasyon\n",
    "def normalize(text):\n",
    "    return ''.join(e.lower() for e in text if e.isalnum() or e.isspace()).strip()\n",
    "\n",
    "# Ba≈ülƒ±k\n",
    "st.title(\"üéå Anime √ñneri Sistemi\")\n",
    "st.write(\"Beƒüendiƒüiniz 1-5 animeyi girin, size benzeyenleri √∂nerelim.\")\n",
    "\n",
    "# Giri≈ü alanƒ±\n",
    "anime_inputs = []\n",
    "for i in range(5):\n",
    "    name = st.text_input(f\"{i+1}. Anime Adƒ±\", \"\")\n",
    "    if name.strip():\n",
    "        anime_inputs.append(name.strip())\n",
    "\n",
    "# Buton\n",
    "if st.button(\"üéØ √ñnerileri Getir\"):\n",
    "    if not anime_inputs:\n",
    "        st.warning(\"L√ºtfen en az 1 anime ismi girin.\")\n",
    "    else:\n",
    "        matched_indices = []\n",
    "        for anime in anime_inputs:\n",
    "            cleaned_input = normalize(anime)\n",
    "            match = process.extractOne(cleaned_input, df[\"base_name\"].tolist(), score_cutoff=80)\n",
    "            if match:\n",
    "                idx = df[df[\"base_name\"] == match[0]].index\n",
    "                if not idx.empty:\n",
    "                    matched_indices.append(idx[0])\n",
    "                    st.success(f\"‚úÖ '{anime}' e≈üle≈üti ‚Üí '{match[0]}'\")\n",
    "            else:\n",
    "                st.warning(f\"‚ö†Ô∏è '{anime}' i√ßin e≈üle≈üme bulunamadƒ±.\")\n",
    "\n",
    "        if not matched_indices:\n",
    "            st.error(\"Hi√ßbir e≈üle≈üme bulunamadƒ±.\")\n",
    "        else:\n",
    "            # TF-IDF vekt√∂r√º\n",
    "            input_vecs = tfidf_matrix[matched_indices]\n",
    "            mean_vec = input_vecs.mean(axis=0)\n",
    "            mean_vec = np.array(mean_vec)\n",
    "\n",
    "            # Benzerlik\n",
    "            cosine_sim = cosine_similarity(mean_vec, tfidf_matrix).flatten()\n",
    "\n",
    "            # Skor hesapla\n",
    "            scored = []\n",
    "            for i, sim in enumerate(cosine_sim):\n",
    "                if i not in matched_indices:\n",
    "                    qual = df.iloc[i]['quality_score'] if not pd.isna(df.iloc[i]['quality_score']) else 0\n",
    "                    score = 0.8 * sim + 0.2 * qual\n",
    "                    scored.append((i, score))\n",
    "\n",
    "            # En iyi 10 √∂neri\n",
    "            top10 = sorted(scored, key=lambda x: x[1], reverse=True)[:10]\n",
    "            results = df.iloc[[i for i, _ in top10]][['name', 'score', 'genres', 'quality_score']].reset_index(drop=True)\n",
    "\n",
    "            st.subheader(\"üîù En ƒ∞yi 10 √ñneri:\")\n",
    "            st.dataframe(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867c1c2-050b-45ea-bfd6-d3c8368b39fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
