{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31a0bf2a-35d4-4d01-a0c2-5ae0c714ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import chardet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb43a9d2-4fc5-4191-9230-a7a5369b5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n",
      "Index(['id', 'name', 'genres', 'type', 'episodes', 'status', 'aired_from',\n",
      "       'aired_to', 'duration_per_ep', 'score', 'scored_by', 'rank', 'rating',\n",
      "       'studios', 'producers', 'image', 'trailer', 'synopsis'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"popular_anime.csv\", \"rb\") as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "df=pd.read_csv(\"popular_anime.csv\",encoding=\"utf-8\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1357e29-8996-45ac-88b3-c0584fc23587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trailer            81.009540\n",
      "aired_to           62.081526\n",
      "producers          53.332177\n",
      "studios            41.245447\n",
      "score              35.476149\n",
      "scored_by          35.476149\n",
      "rank               23.809193\n",
      "genres             21.054640\n",
      "synopsis           18.622723\n",
      "aired_from          3.313096\n",
      "episodes            2.702515\n",
      "rating              2.511709\n",
      "type                0.301821\n",
      "name                0.000000\n",
      "duration_per_ep     0.000000\n",
      "status              0.000000\n",
      "image               0.000000\n",
      "id                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "emptydatapercentage=df.isnull().mean()*100\n",
    "print(emptydatapercentage.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d05e240d-07e5-4d2a-8685-1e4037f3508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aired_to', 'trailer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop=emptydatapercentage[emptydatapercentage>60].index\n",
    "print(cols_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55838012-b932-490f-96d1-66653acd7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.base.Index'>\n",
      "Index(['aired_to', 'trailer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(type(cols_to_drop))\n",
    "print(cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd033520-d5af-4f8d-b9ac-ba3e5693ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'genres', 'type', 'episodes', 'status', 'aired_from', 'aired_to', 'duration_per_ep', 'score', 'scored_by', 'rank', 'rating', 'studios', 'producers', 'image', 'trailer', 'synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13aa3242-9317-402f-8f43-8e9a4ec4006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   int64\n",
      "name                object\n",
      "genres              object\n",
      "type                object\n",
      "episodes           float64\n",
      "status              object\n",
      "aired_from          object\n",
      "aired_to            object\n",
      "duration_per_ep     object\n",
      "score              float64\n",
      "scored_by          float64\n",
      "rank               float64\n",
      "rating              object\n",
      "studios             object\n",
      "producers           object\n",
      "image               object\n",
      "trailer             object\n",
      "synopsis            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f99a24a-e221-47f2-9aab-14e85afa341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aired_from'] = pd.to_datetime(df['aired_from'], errors='coerce')\n",
    "\n",
    "\n",
    "# duration_per_ep'deki süreyi dakikaya çevir\n",
    "df['duration_per_ep_minutes'] = df['duration_per_ep'].str.extract('(\\\\d+)').astype(float)\n",
    "\n",
    "# Kategorik sütunları dönüştür\n",
    "df['status'] = df['status'].astype('category')\n",
    "df['type'] = df['type'].astype('category')\n",
    "df['rating'] = df['rating'].astype('category')\n",
    "df['genres'] = df['genres'].astype('category')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca653ed4-e2b7-47bd-ab08-8fe37fe77c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                       int64\n",
      "name                                    object\n",
      "genres                                category\n",
      "type                                  category\n",
      "episodes                               float64\n",
      "status                                category\n",
      "aired_from                 datetime64[ns, UTC]\n",
      "aired_to                                object\n",
      "duration_per_ep                         object\n",
      "score                                  float64\n",
      "scored_by                              float64\n",
      "rank                                   float64\n",
      "rating                                category\n",
      "studios                                 object\n",
      "producers                               object\n",
      "image                                   object\n",
      "trailer                                 object\n",
      "synopsis                                object\n",
      "duration_per_ep_minutes                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31be3497-f034-4dac-9570-1ef94f1fe171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trailer            81.009540\n",
      "aired_to           62.081526\n",
      "producers          53.332177\n",
      "studios            41.245447\n",
      "score              35.476149\n",
      "scored_by          35.476149\n",
      "rank               23.809193\n",
      "genres             21.054640\n",
      "synopsis           18.622723\n",
      "aired_from          3.313096\n",
      "episodes            2.702515\n",
      "rating              2.511709\n",
      "type                0.301821\n",
      "name                0.000000\n",
      "duration_per_ep     0.000000\n",
      "status              0.000000\n",
      "image               0.000000\n",
      "id                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(emptydatapercentage.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91260150-5b4e-42ac-be18-6a3f5a66f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['studios','producers','aired_to','image','trailer'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26576df4-bc58-4e7b-9384-2bd096646b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['genres', 'type', 'status', 'rating']:\n",
    "    if col in df.columns and df[col].dtype.name == 'category':\n",
    "        if 'Unknown' not in df[col].cat.categories:\n",
    "            df[col] = df[col].cat.add_categories(['Unknown'])\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "for col in ['episodes', 'duration_per_ep_minutes','score','scored_by','rank','rating']:\n",
    "    if col in df.columns and df[col].dtype.name == 'category':\n",
    "        if '-1,0,23' not in df[col].cat.categories:\n",
    "            df[col] = df[col].cat.add_categories([-1,0,23])\n",
    "    \n",
    "\n",
    "df.fillna({\n",
    "    'name': 'Unknown',\n",
    "    'genres': 'Unknown',\n",
    "    'type': df['type'].mode()[0],\n",
    "    'episodes': 23,\n",
    "    'status': df['status'].mode()[0],\n",
    "    'aired_from': pd.Timestamp('2000-01-01'),\n",
    "    'aired_to': pd.Timestamp('2000-01-01'),\n",
    "    'duration_per_ep_minutes': 24,\n",
    "    'score': 0,\n",
    "    'scored_by': df['scored_by'].median(),\n",
    "    'rank': -1,\n",
    "    'rating': 0,\n",
    "    'image': 'No image',\n",
    "    'trailer': 'No trailer',\n",
    "    'synopsis': 'No synopsis available'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc0b48ef-e900-437f-ad93-ed8efb4fda5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28825 entries, 0 to 28824\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   id                       28825 non-null  int64   \n",
      " 1   name                     28825 non-null  object  \n",
      " 2   genres                   28825 non-null  category\n",
      " 3   type                     28825 non-null  category\n",
      " 4   episodes                 28825 non-null  float64 \n",
      " 5   status                   28825 non-null  category\n",
      " 6   aired_from               28825 non-null  object  \n",
      " 7   duration_per_ep          28825 non-null  object  \n",
      " 8   score                    28825 non-null  float64 \n",
      " 9   scored_by                28825 non-null  float64 \n",
      " 10  rank                     28825 non-null  float64 \n",
      " 11  rating                   28825 non-null  category\n",
      " 12  synopsis                 28825 non-null  object  \n",
      " 13  duration_per_ep_minutes  28825 non-null  float64 \n",
      "dtypes: category(4), float64(5), int64(1), object(4)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffe6d073-bd44-448e-b422-09abbfdc4b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "TV            8249\n",
      "Movie         4836\n",
      "OVA           4166\n",
      "Music         4087\n",
      "ONA           4076\n",
      "Special       1779\n",
      "TV Special     745\n",
      "CM             504\n",
      "PV             296\n",
      "Unknown         87\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a272084-e4ef-4a27-8f60-58ac93bcf64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- name ---\n",
      "name\n",
      "Spirit Guardians                               5\n",
      "Promise                                        5\n",
      "Happy Heroes: Rebel Rescue                     4\n",
      "Cyborg 009                                     4\n",
      "Meow Meow Japanese History                     4\n",
      "                                              ..\n",
      "Pyuu to Fuku! Jaguar: Ima, Fuki ni Yukimasu    1\n",
      "Argento Soma: Hitori to Hitori                 1\n",
      "Yurumates                                      1\n",
      "The Fleet of the Rising Sun                    1\n",
      "Marin X                                        1\n",
      "Name: count, Length: 28350, dtype: int64\n",
      "\n",
      "\n",
      "--- genres ---\n",
      "genres\n",
      "Unknown                                            6069\n",
      "Comedy                                             2621\n",
      "Fantasy                                            1462\n",
      "Hentai                                             1293\n",
      "Slice of Life                                       821\n",
      "                                                   ... \n",
      "Boys Love, Drama, Horror, Mystery, Supernatural       1\n",
      "Boys Love, Drama, Horror, Hentai                      1\n",
      "Boys Love, Drama, Hentai                              1\n",
      "Boys Love, Drama, Fantasy, Sci-Fi, Supernatural       1\n",
      "Adventure, Mystery, Sci-Fi, Slice of Life             1\n",
      "Name: count, Length: 936, dtype: int64\n",
      "\n",
      "\n",
      "--- type ---\n",
      "type\n",
      "TV            8249\n",
      "Movie         4836\n",
      "OVA           4166\n",
      "Music         4087\n",
      "ONA           4076\n",
      "Special       1779\n",
      "TV Special     745\n",
      "CM             504\n",
      "PV             296\n",
      "Unknown         87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- status ---\n",
      "status\n",
      "Finished Airing     27813\n",
      "Not yet aired         632\n",
      "Currently Airing      380\n",
      "Unknown                 0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- aired_from ---\n",
      "aired_from\n",
      "2000-01-01 00:00:00          955\n",
      "2012-01-01 00:00:00+00:00    159\n",
      "2011-01-01 00:00:00+00:00    156\n",
      "2010-01-01 00:00:00+00:00    143\n",
      "2019-01-01 00:00:00+00:00    140\n",
      "                            ... \n",
      "2012-02-23 00:00:00+00:00      1\n",
      "2002-09-09 00:00:00+00:00      1\n",
      "2009-06-30 00:00:00+00:00      1\n",
      "1981-09-07 00:00:00+00:00      1\n",
      "1978-07-31 00:00:00+00:00      1\n",
      "Name: count, Length: 9252, dtype: int64\n",
      "\n",
      "\n",
      "--- duration_per_ep ---\n",
      "duration_per_ep\n",
      "24 min per ep         2078\n",
      "23 min per ep         1819\n",
      "2 min                 1687\n",
      "3 min                 1629\n",
      "4 min                 1198\n",
      "                      ... \n",
      "24 sec                   1\n",
      "2 hr 35 min              1\n",
      "1 hr 7 min per ep        1\n",
      "1 hr 16 min per ep       1\n",
      "43 sec per ep            1\n",
      "Name: count, Length: 345, dtype: int64\n",
      "\n",
      "\n",
      "--- rating ---\n",
      "rating\n",
      "PG-13 - Teens 13 or older         10413\n",
      "G - All Ages                       8963\n",
      "PG - Children                      4354\n",
      "R - 17+ (violence & profanity)     1586\n",
      "Rx - Hentai                        1575\n",
      "R+ - Mild Nudity                   1210\n",
      "Unknown                             724\n",
      "-1                                    0\n",
      "0                                     0\n",
      "23                                    0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- synopsis ---\n",
      "synopsis\n",
      "No synopsis available                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           5368\n",
      "Music video for the so                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            64\n",
      "Music video for the song                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          51\n",
      "Music video for the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               46\n",
      "Music video for t                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 46\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ... \n",
      "In a world where only Pokémon live, one Hikozaru wishes to be part of Pukurin Guild—a large area where Exploration Teams gather and work. Intimidated by the apparent strength of the guild members and the guild's security, Hikozaru runs away, stumbling over an unconscious Pochama in the middle of his escape. The Pochama wakes up and is immediately shocked by both a talking Hikozaru as well as his own appearance—because Pochama knows that he is actually a human!\\n\\nWith Pochama having no memories aside from previously being human (as well as countless questions about his new body), Hikozaru suggests that he ask the leader of Pukurin Guild for help. While Guildmaster Pukurin may not have answers about Pochama's transformation, he decides to make Pochama and Hikozaru an Exploration Team, which HIkozaru calls Pokédans. For their first mission, the duo must get a Gabite Scale by going to Labyrinth Cave with Kimawari!       1\n",
      "After destroying the Zorbados Empire, the Jyusenki-tai/Cyber Beast Force has expanded and are training new recruits. But after failing to stop a monster that seems to be a remnant of the Zorbados Empire from destroying a city, the CBF is thrown in jail. Now the CBF have to escape from jail and find out what was behind the monster t                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "Di Gi Charat (call her Dejiko for short) and Petit Charat (the cute little charat) come down to Earth, where they want to be idols, or something like that. Rabi~en~Rose (a random girl with bunny ears) decides they're in her way of becoming an idol herself. They all end up working at Gamers, where various otaku, children, and humanoid fingers walk in and act like morons.\\n\\nContains:\\nGema no Sumika\\nTsusode shiu Engekidan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      "Unaired series episode in                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      "A Korean animated movie mixing Mecha w                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      "Name: count, Length: 21992, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.select_dtypes(include=['object', 'category']):\n",
    "    print(f\"--- {col} ---\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ae11020-207f-4f20-bd91-271537b72113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11c6fd3a-730f-4693-b03e-219e26b5d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_anime_name(name):\n",
    "    name = re.sub(r\"Season\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Final\\s*Season.*\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Part\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"\\s*:\\s*.*$\", \"\", name, flags=re.IGNORECASE)  # isimden sonrasını sil\n",
    "    name = name.strip()\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d58b1cae-0993-4289-aa21-95fd46c39fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset yükle\n",
    "df = pd.read_csv('popular_anime.csv')\n",
    "\n",
    "# synopsis sütununu doldur\n",
    "df['synopsis'] = df['synopsis'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "476636fe-b52f-4862-8459-09884a97b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_clean'] = df['name'].apply(clean_anime_name)\n",
    "df['name_lower'] = df['name'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c19e37f-7922-4887-8dbd-26190bd77d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_type_group(x):\n",
    "    if x in ['TV', 'OVA', 'ONA', 'Special']:\n",
    "        return 'TV_GROUP'\n",
    "    elif x == 'Movie':\n",
    "        return 'MOVIE_GROUP'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "df['type_group'] = df['type'].apply(map_type_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf295884-4d64-4ec0-af68-aab7e4b7382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN isimleri sil\n",
    "df_clean = df.dropna(subset=['name_clean'])\n",
    "\n",
    "# en yüksek skoru al\n",
    "df_dedup = (\n",
    "    df_clean\n",
    "    .sort_values('score', ascending=False)\n",
    "    .drop_duplicates(subset=['name_clean', 'type_group'], keep='first')\n",
    ")\n",
    "\n",
    "# TV ve Movie DataFrame'leri oluştur\n",
    "tv_final_df = df_dedup[df_dedup['type_group'] == 'TV_GROUP']\n",
    "movie_final_df = df_dedup[df_dedup['type_group'] == 'MOVIE_GROUP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f373536-5a61-4175-a768-c16e7a10d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TV synopsis listesi\n",
    "tv_synopsis_list = tv_final_df['synopsis'].tolist()\n",
    "# 1. Veri temizliği (zaten yapmışsın ama synopsis uzunluk filtresi ekleniyor)\n",
    "\n",
    "df_filtered = df[df['synopsis'].str.len() >= 30].copy()\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df_filtered['synopsis'])\n",
    "\n",
    "# TF-IDF vektörizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Movie synopsis listesi\n",
    "movie_synopsis_list = movie_final_df['synopsis'].tolist()\n",
    "\n",
    "vectorizer_movie = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix_movie = vectorizer_movie.fit_transform(movie_synopsis_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "144f2f34-2f6f-4aa2-8256-76fd320451e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\ertugrultetik\\anaconda3\\lib\\site-packages (3.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6d380eef-7949-45a8-b7f3-df1b2e852e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6d0c755-4883-43dd-965a-d02f0659aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_anime_name(name):\n",
    "    if pd.isnull(name): return \"\"\n",
    "    name = re.sub(r\"Season\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Final\\s*Season.*\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"Part\\s*\\d+\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", name)\n",
    "    return name.strip().lower()\n",
    "\n",
    "def normalize(text): return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd76da75-b28b-4b92-8231-43011b0a86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TV ve Movie veri setlerine güvenli bir şekilde 'source' ekle\n",
    "tv_final_df = tv_final_df.copy()\n",
    "tv_final_df[\"source\"] = \"tv\"\n",
    "\n",
    "movie_final_df = movie_final_df.copy()\n",
    "movie_final_df[\"source\"] = \"movie\"\n",
    "remove_types = [\"Special\", \"OVA\", \"ONA\", \"Music\", \"Recap\"]\n",
    "\n",
    "def clean_df(df):\n",
    "    return df[\n",
    "        df[\"synopsis\"].notnull() &\n",
    "        df[\"name\"].notnull() &\n",
    "        (df[\"score\"].fillna(0) >= 5.0) &\n",
    "        (~df[\"type\"].isin(remove_types)) &\n",
    "        (df[\"episodes\"].fillna(2) > 1)\n",
    "    ]\n",
    "\n",
    "tv_final_df = clean_df(tv_final_df)\n",
    "movie_final_df = clean_df(movie_final_df)\n",
    "\n",
    "# Birleştir ve yeni df_all'u garanti bir kopya olarak al\n",
    "df_all = pd.concat([tv_final_df, movie_final_df], ignore_index=True).copy()\n",
    "\n",
    "# Güvenli şekilde temizleme işlemleri\n",
    "df_all[\"base_name\"] = df_all[\"name\"].apply(clean_anime_name).str.lower()\n",
    "\n",
    "df_all[\"combined_text\"] = (\n",
    "    df_all[\"synopsis\"].fillna(\"\") + \" \" +\n",
    "    df_all[\"genres\"].fillna(\"\") + \" \" +\n",
    "    df_all[\"type\"].fillna(\"\") + \" \" +\n",
    "    df_all[\"rating\"].fillna(\"\")\n",
    ").str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "14033af8-f6e0-4fb2-8970-7b0c8a01bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def fuzzy_merge(df_base, df_additional, on='base_name', threshold=90):\n",
    "    matches = []\n",
    "    for name in df_base[on]:\n",
    "        match = process.extractOne(name, df_additional['English name cleaned'], scorer=fuzz.token_sort_ratio)\n",
    "        if match and match[1] >= threshold:\n",
    "            row = df_additional[df_additional['English name cleaned'] == match[0]]\n",
    "            if not row.empty:\n",
    "                row_data = {\n",
    "                    \"Score\": row[\"Score\"].values[0] if \"Score\" in row else np.nan,\n",
    "                    \"Rank\": row[\"Rank\"].values[0] if \"Rank\" in row else np.nan,\n",
    "                    \"Popularity\": row[\"Popularity\"].values[0] if \"Popularity\" in row else np.nan\n",
    "                }\n",
    "                matches.append(pd.Series(row_data))\n",
    "            else:\n",
    "                matches.append(pd.Series({\"Score\": np.nan, \"Rank\": np.nan, \"Popularity\": np.nan}))\n",
    "        else:\n",
    "            matches.append(pd.Series({\"Score\": np.nan, \"Rank\": np.nan, \"Popularity\": np.nan}))\n",
    "    scores_df = pd.DataFrame(matches).reset_index(drop=True)\n",
    "    return pd.concat([df_base.reset_index(drop=True), scores_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9410ef52-0454-44e5-aa14-70fd14b0e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix_all = vectorizer.fit_transform(df_all[\"combined_text\"])\n",
    "# anime-dataset-2023.csv dosyasını oku\n",
    "df2 = pd.read_csv(\"anime-dataset-2023.csv\")\n",
    "df2[\"English name cleaned\"] = df2[\"English name\"].fillna(df2[\"Name\"]).apply(clean_anime_name)\n",
    "# Gereksiz kolonları sil\n",
    "drop_cols = [\n",
    "    \"Producers\", \"Licensors\", \"Premiered\",\n",
    "    \"Broadcast\", \"Opening Theme\", \"Ending Theme\", \"Background\"\n",
    "]\n",
    "df_all.drop(columns=[col for col in drop_cols if col in df_all.columns], inplace=True)\n",
    "# Merge et\n",
    "df_all = fuzzy_merge(df_all, df2)\n",
    "df_all[\"Score\"] = pd.to_numeric(df_all[\"Score\"], errors=\"coerce\")\n",
    "\n",
    "# Satır bazlı temizlik\n",
    "df_all = df_all[df_all[\"synopsis\"].notnull() & df_all[\"name\"].notnull()]\n",
    "df_all = df_all[df_all[\"Score\"].fillna(0) > 4]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5f1e8aa4-fad3-4a1e-8130-ef99bc693eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Gerekli kolonlar\n",
    "required_cols = [\"Score\", \"Rank\", \"Popularity\"]\n",
    "\n",
    "# Eksik olan kolonları ekle ve tipleri dönüştür\n",
    "for col in required_cols:\n",
    "    if col not in df_all.columns:\n",
    "        df_all[col] = np.nan\n",
    "\n",
    "# Tip kontrolü: Sayısal değilse dönüştür\n",
    "for col in required_cols:\n",
    "    df_all[col] = pd.to_numeric(df_all[col], errors='coerce')\n",
    "\n",
    "# Ortalamayla doldur\n",
    "df_all[required_cols] = df_all[required_cols].fillna(df_all[required_cols].mean())\n",
    "\n",
    "# Normalize et\n",
    "scaler = MinMaxScaler()\n",
    "df_all[[\"norm_score\", \"norm_rank\", \"norm_popularity\"]] = scaler.fit_transform(df_all[required_cols])\n",
    "\n",
    "# Quality Score hesapla (score yüksek, rank/popularity düşük iyidir)\n",
    "df_all[\"quality_score\"] = (\n",
    "    df_all[\"norm_score\"] * 0.5 +\n",
    "    (1 - df_all[\"norm_rank\"]) * 0.3 +\n",
    "    (1 - df_all[\"norm_popularity\"]) * 0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c94a1d9c-9896-43b3-89ba-62431eee50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d2901452-dfaf-48ca-947e-f9586bcb4111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Lütfen en az 1, en fazla 5 anime ismi giriniz.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1. anime ismi (bitirmek için boş bırak ve Enter'a bas):  91 days\n",
      "2. anime ismi (bitirmek için boş bırak ve Enter'a bas):   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ '91 days' eşleşti → '91 days'\n",
      "\n",
      "🎯 Final Skor ile En İyi 10 Anime Önerisi:\n",
      "                                    name  score                                             genres  quality_score\n",
      "0  JoJo's Bizarre Adventure: Golden Wind   8.58                                  Action, Adventure       0.932779\n",
      "1                                 Erased   8.30                                  Mystery, Suspense       0.897636\n",
      "2        The Eminence in Shadow Season 2   8.29                            Action, Comedy, Fantasy       0.895557\n",
      "3                      The Tatami Galaxy   8.55  Award Winning, Comedy, Mystery, Romance, Suspense       0.927375\n",
      "4        Fruits Basket: The Final Season   8.95                       Drama, Romance, Supernatural       0.981753\n",
      "5                            Banana Fish   8.45                 Action, Adventure, Drama, Suspense       0.918834\n",
      "6                 The Promised Neverland   8.48                                  Mystery, Suspense       0.924767\n",
      "7                       Samurai Champloo   8.52                          Action, Adventure, Comedy       0.924003\n",
      "8                       To Your Eternity   8.34                     Adventure, Drama, Supernatural       0.902617\n",
      "9        Bleach: Thousand-Year Blood War   8.99                    Action, Adventure, Supernatural       0.990863\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ Kullanılacak veriyi filtrele (örneğin synopsis kısa olanları at)\n",
    "df_filtered = df_all[df_all[\"synopsis\"].str.len() >= 30].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)  # index karışıklığını önlemek için sıfırla\n",
    "\n",
    "# 2️⃣ TF-IDF matrisini oluştur\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix_filtered = vectorizer.fit_transform(df_filtered[\"combined_text\"])\n",
    "\n",
    "# 3️⃣ Kullanıcıdan anime isimleri al\n",
    "print(\"📥 Lütfen en az 1, en fazla 5 anime ismi giriniz.\")\n",
    "user_inputs = []\n",
    "while len(user_inputs) < 5:\n",
    "    anime_name = input(f\"{len(user_inputs)+1}. anime ismi (bitirmek için boş bırak ve Enter'a bas): \").strip()\n",
    "    if anime_name == '':\n",
    "        break\n",
    "    user_inputs.append(anime_name)\n",
    "\n",
    "if not user_inputs:\n",
    "    print(\"❌ En az bir anime ismi girmelisiniz.\")\n",
    "    exit()\n",
    "\n",
    "# 4️⃣ Anime isimlerini fuzzy match ile eşleştir\n",
    "matched_indices = []\n",
    "for anime in user_inputs:\n",
    "    cleaned_input = normalize(anime)\n",
    "    best_match = process.extractOne(cleaned_input, df_filtered[\"base_name\"].tolist(), score_cutoff=80)\n",
    "    if best_match:\n",
    "        idx = df_filtered[df_filtered[\"base_name\"] == best_match[0]].index\n",
    "        if not idx.empty:\n",
    "            matched_indices.append(idx[0])\n",
    "        print(f\"✅ '{anime}' eşleşti → '{best_match[0]}'\")\n",
    "    else:\n",
    "        print(f\"⚠️ '{anime}' için eşleşme bulunamadı.\")\n",
    "\n",
    "if not matched_indices:\n",
    "    print(\"❌ Hiçbir geçerli eşleşme bulunamadı.\")\n",
    "    exit()\n",
    "\n",
    "# 5️⃣ TF-IDF ortalama vektörünü hesapla\n",
    "input_vecs = tfidf_matrix_filtered[matched_indices]\n",
    "mean_vec = input_vecs.mean(axis=0)\n",
    "mean_vec = np.array(mean_vec)\n",
    "\n",
    "# 6️⃣ Cosine similarity ile benzerlikleri bul\n",
    "cosine_sim = cosine_similarity(mean_vec, tfidf_matrix_filtered).flatten()\n",
    "\n",
    "# 7️⃣ Final skoru hesapla (benzerlik ve kalite skoru birlikte)\n",
    "scored = []\n",
    "for i, sim in enumerate(cosine_sim):\n",
    "    qual = df_filtered.iloc[i]['quality_score'] if not pd.isna(df_filtered.iloc[i]['quality_score']) else 0\n",
    "    final_score = 0.8 * sim + 0.2 * qual\n",
    "    scored.append((i, final_score))\n",
    "\n",
    "\n",
    "# 8️⃣ En iyi 10 sonucu al (kullanıcının girdiklerini çıkar)\n",
    "top10 = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "top10 = [item for item in top10 if item[0] not in matched_indices][:10]\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# 9️⃣ Önerileri yazdır\n",
    "print(\"\\n🎯 Final Skor ile En İyi 10 Anime Önerisi:\")\n",
    "recommendations = df_filtered.iloc[[i for i, _ in top10]][['name', 'score', 'genres', 'quality_score']]\n",
    "recommendations.reset_index(drop=True, inplace=True)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da01e9e1-00e5-4692-9042-cb77879955c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score   Rank  Popularity\n",
      "1   9.10    1.0         3.0\n",
      "2   9.07    3.0        13.0\n",
      "3   8.94   16.0       138.0\n",
      "4   8.54  107.0         1.0\n",
      "5   8.41  170.0       357.0\n"
     ]
    }
   ],
   "source": [
    "print(df_all[['Score', 'Rank', 'Popularity']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e450db34-4b31-4c62-ac67-d16be8430ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8233, 21)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['synopsis'].str.len() < 30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "67b43e76-925f-4a74-ab41-4bc710d77ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (4392, 29401)\n",
      "df_all shape: (2723, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF shape:\", tfidf_matrix_all.shape)\n",
    "print(\"df_all shape:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7d8b8310-e509-4e36-96fb-55fabc8e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"anime_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f2951ac-65fc-4222-b3ce-8257e5bd78c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 14:54:08.995 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your preprocessed anime dataset here\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"anime_cleaned.csv\")  # senin temizlenmiş df_filtered.csv\n",
    "    df = df[df[\"synopsis\"].str.len() >= 30].copy()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "@st.cache_resource\n",
    "def vectorize_text(df):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['combined_text'])\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "vectorizer, tfidf_matrix = vectorize_text(df)\n",
    "\n",
    "# Normalizasyon\n",
    "def normalize(text):\n",
    "    return ''.join(e.lower() for e in text if e.isalnum() or e.isspace()).strip()\n",
    "\n",
    "# Başlık\n",
    "st.title(\"🎌 Anime Öneri Sistemi\")\n",
    "st.write(\"Beğendiğiniz 1-5 animeyi girin, size benzeyenleri önerelim.\")\n",
    "\n",
    "# Giriş alanı\n",
    "anime_inputs = []\n",
    "for i in range(5):\n",
    "    name = st.text_input(f\"{i+1}. Anime Adı\", \"\")\n",
    "    if name.strip():\n",
    "        anime_inputs.append(name.strip())\n",
    "\n",
    "# Buton\n",
    "if st.button(\"🎯 Önerileri Getir\"):\n",
    "    if not anime_inputs:\n",
    "        st.warning(\"Lütfen en az 1 anime ismi girin.\")\n",
    "    else:\n",
    "        matched_indices = []\n",
    "        for anime in anime_inputs:\n",
    "            cleaned_input = normalize(anime)\n",
    "            match = process.extractOne(cleaned_input, df[\"base_name\"].tolist(), score_cutoff=80)\n",
    "            if match:\n",
    "                idx = df[df[\"base_name\"] == match[0]].index\n",
    "                if not idx.empty:\n",
    "                    matched_indices.append(idx[0])\n",
    "                    st.success(f\"✅ '{anime}' eşleşti → '{match[0]}'\")\n",
    "            else:\n",
    "                st.warning(f\"⚠️ '{anime}' için eşleşme bulunamadı.\")\n",
    "\n",
    "        if not matched_indices:\n",
    "            st.error(\"Hiçbir eşleşme bulunamadı.\")\n",
    "        else:\n",
    "            # TF-IDF vektörü\n",
    "            input_vecs = tfidf_matrix[matched_indices]\n",
    "            mean_vec = input_vecs.mean(axis=0)\n",
    "            mean_vec = np.array(mean_vec)\n",
    "\n",
    "            # Benzerlik\n",
    "            cosine_sim = cosine_similarity(mean_vec, tfidf_matrix).flatten()\n",
    "\n",
    "            # Skor hesapla\n",
    "            scored = []\n",
    "            for i, sim in enumerate(cosine_sim):\n",
    "                if i not in matched_indices:\n",
    "                    qual = df.iloc[i]['quality_score'] if not pd.isna(df.iloc[i]['quality_score']) else 0\n",
    "                    score = 0.8 * sim + 0.2 * qual\n",
    "                    scored.append((i, score))\n",
    "\n",
    "            # En iyi 10 öneri\n",
    "            top10 = sorted(scored, key=lambda x: x[1], reverse=True)[:10]\n",
    "            results = df.iloc[[i for i, _ in top10]][['name', 'score', 'genres', 'quality_score']].reset_index(drop=True)\n",
    "\n",
    "            st.subheader(\"🔝 En İyi 10 Öneri:\")\n",
    "            st.dataframe(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867c1c2-050b-45ea-bfd6-d3c8368b39fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
